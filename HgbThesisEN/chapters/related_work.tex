\chapter{Related Work}
\label{cha:Related_Work}
This chapter summarizes the state-of-the-art concepts for microservice security and for public key based authentication.
Furthermore the technologies, which are used to implement the later discussed authentication mechanisms are described.
This chapter aims to give a good understanding of the whole domain and not only about service-to-service authentication.

\section{Microserivce Security}
Siriwardena and Dias~\cite{dias2020microservices} gave an exhensive guide of all topics related to microservice security. 
They separated the security of an microservice deployment into edge-level security and service-level security.
The microservice architecture is based on separating the system in multiple parts.
It is not sufficient to secure the system only on the edge-level or only on the service-level.
Each part of the system has to be secured properly regarding confidentiality, authentication and authorization.

\subsection{Edge-level security}
Edge-level security is defined as the security mechanisms that protect the resources within the deployment from attackers outside the deployment.
The API Gateway is responsible for the edge security it is the only entry point to the microservice deployment.
All requests targeted for the APIs of the services are intercepted by the API Gateway.
After validation of the requests, it dispatches the requests to the microservices.
The main tasks of an API Gateway are authentication of the end user, authorization, and throttling.
It authenticates the end user using access tokens, which come from access delegation technologies like OAuth 2.0 or Open ID Connect~\cite{siriwardena2014advanced}.
Due to outourcing the end user authentication to the API Gateway, the end user authentication has to be performed only once and not by every service.
The API Gateway is able to perform simple authorization assertions. 
As soon as the authorization gets more granular, the microservices have to perform it on their own, because the API Gateway does not know the business logic.

\subsection{Service-level security}
Service-level security is defined as the security mechanisms that protect the communication among the microservices.
According to Barabanov and Makrushin~\cite{barabanov2020authentication} service-level security can be decomposed into the sub functions service-level authentication, service-level authorization, and external identity propagation.
Service-level security can either be implemented by the microservices themselves or by a service-mesh.
A service mesh can be seen as a dedicated infrastructure layer, which manages the service-to-service communication of containerized services.
In a typical microservice deployment with a service mesh, each microservice has its service proxy, which works transparently~\cite{dias2020microservices}
The servce mesh is responsible for service discovery, routing, load balancing, traffic configuration, authentication authorization and monitoring~\cite{chandramouli2019microservices}.

\subsubsection{Service-to-service-authentication} 
\label{sec:service-to-service-authentication}
Authentication is the process of identifying the communication partner to protect a system from spoofing.
Since the communication among microservices is done using remote calls, their communication has to provide authentication.
Service-to-service authentication can be implemented in the following ways~\cite{dias2020microservices}:
\begin{itemize}
    \item Trust the Network (TTN)
    \item mutual Transport Layer Security (mTLS)
    \item self signed JSON Web Tokens (JWTs)
\end{itemize}
Trust the Network is a security approach, that is based on the assertion that nobody has access to the components within a network perimeter.
All components rely on the network security.
Nevertheless, internal misbehaviour can lead to exploits allowing attackers intrude into the network perimeter and exploit the microservices~\cite{zaheer2019eztrust}. 
Therefore the industry is heading towards zero-trust networks and the TTN approach became deprecated~\cite{dias2020microservices}.

Service-to-servie authentication based on mTLS and self signed JWTs will be discussed in more detail in chapter~\ref{cha:authentication_mechanisms}.

\subsubsection{Service-level authorization} 
\label{sec:service-level-authorization}
Authorization defines the tasks that a principal is allowed to perform on a system.
It requires that the principal is already authenticated because the authorization is performed based on the identity~\cite{siriwardena2014advanced}. 
Service-level authorization gives the microservices more control to enforce access control.
The authorization is usually performed using policy decision point (PDP) models like the centralized PDP model or the embedded PDP model~\cite{dias2020microservices, barabanov2020authentication}.
Proper service-to-service mechanisms are a precondition for service-to-service authorization, since the authorization can be bypassed with insufficient authentication~\cite{siriwardena2014advanced}.

\subsubsection{External entity identity propagation} 
\label{sec:external-entity-identity-propagation}
In order to perform the authorization correctly, the services have to know the context of the caller.
The most popular technic for identity propagation is extracting the context of the user within JSON Web Tokens.
The tokens are passed between the microservices and the API Gateway.
The propagated identity of the user can be extracted from the token, and the token's signature must be checked.
The microservices can perform authorization based on the identity of the client~\cite{barabanov2020authentication, dias2020microservices}.
The chosen authentication mechanism do have an impact on the identity propagation, this will be discussed in more detail in chapter~\ref{cha:authentication_mechanisms}.

\section{Public key-Based Authentication}
Authentication can be performed in many ways two common approaches are symmetric cryptography and public key cryptography.
Both authentication mechanisms which are discussed in chapter~\ref{cha:authentication_mechanisms} are based on public key cryptography.
Public key cryptography provides higher security than symmetric cryptography.
Therefore it is the preferred method to implement authentication mechanisms, altough it requires higher computation and communication costs than symmetric cryptography~\cite{pubkeycrypto}.

\subsection{Public key cryptography}
Public key cryptography can also be called asymmetric cryptography, because the main idea is, that different keys are used for encryption and decryption~\cite{anderson2020security}.
Each participant is required to own at least on key pair.
A key pair consists of a public key that is available to everyone and a private key that is only known by the owner of the key pair.
Encrypting a message with the public key, allows many people to encrypt messages in a way that only the person, which owns the private key can read them.
Furthermore it allows one person to encrypt messages, in a way, that many people can read it, by encrypting the message with the private key~\cite{henriques2017using}.
This is also known under the term digital signature. 
Digital signatures can be used to provide authentication and integrity for messages~\cite{anderson2020security}.

The commonly used algorithm for digital signatures is RSA.
RSA is based on factoring and the encryption key consists of the modulus $N$ which is hard to factor.
The modulus $N$ is calculated by multiplying to large prime number $p$ and $q$ with each other.
Additionally the encryption key has a public factor $e$ that has no common factors with either $p-1$ or $q-1$.
The private key consists of the factors $p$ and $q$, which have to be kept secret.
The person that knows the private key, can encrypt a message using the following formular, where $M$ is the message and $C$ is the encrypted message~\cite{anderson2020security}:
\begin{displaymath}
	C = M^e (mod N)
\end{displaymath}
An encrypted message can be decryped using the following formular:
\begin{displaymath}
	M = \sqrt[e]{C (mod N)}
\end{displaymath}
Only the owner of the private key can simply calculate the message from the cipher, using the Fermat's theorem\footnote{See~\cite{anderson2020security} for further information}.

The problem with assymmetric cryptography is, that the encryption and decryption times are worse than using symmetric cryptography.
The restriction to use only assymmetric cryptography could decrease the performance of the system.
Therefore it is common sense to use hybrid systems, that exchange symmetric keys using assymmetric cryptography, but then use symmetric cryptography for the encryption and decryption of messages like it is done in TLS~\cite{henriques2017using}.
Henriques~\cite{henriques2017using} showed, that this mechanism does not result in any correlations between the keys and that the performance of the system can be improved using a hybrid approach.

\subsection{PKI}
Public key cryptography assumes that the receiver of a message already knows and trsusts the public key of the sender.
Public Key Infrastructues (PKI) are used to achieve this assertion.
They are responsible for providing a possibility to retrieve the public key of a participant in a trusted way.
This is done using Certificate Authorities (CA) and certificates~\cite{anderson2020security}.

A PKI can either be a open PKI (global) or a closed PKI (self-hosted).
Closed PKIs have a specific bounded context~\cite{hlavaty2003risk}.
A common use case for closed PKIs are microservice deployments, because they are usually company intern and have a specific bounded context~\cite{dias2020microservices}.
The project which is reviewed in chapter~\ref{cha:project_structure} makes use of a closed PKI.
Closed PKIs are a popular option, because they allow risk management and provide secrecy of its code~\cite{hlavaty2003risk}.
Open PKIs can be inspected by the public and based on the inspection it is determined whether the PKI is trusted or not.
Certificates are retrieved, by making partnerships with CAs.
The main advantage is, that no proprietary software is needed, since the PKIs are managed by the PKI vendors~\cite{hlavaty2003risk}.

\subsection{Key Management} \label{sec:key_management}
Key management is one requirement for public key based authentication mechanism.
It results in being the most challenging part for the later discussed authentication mechanisms.
When the key management of a system is very weak, it will have consequences to all parts of the system.
Especially service-to-service authentication is affected by the quality of the key management.
The authentication mechanism can be as secure as possible, but when the keys are compromised, the authentication mechanism can't stay secure~\cite{dias2020microservices, fumy1993principles}.
According to Fumy et. al.~\cite{fumy1993principles}, a key management service has to implement the following tasks:
\begin{description}
	\item[Entity Registration:] The service must provide a procedure to create a link between an authenticated identity and its keys.
	\item[Key Generation:] The service must provide a procedure to create key pairs with good cryptographic quality.
	\item[Certification:] The service must provide a procedure for issuing certificates. Certification is oftenly a part of key distribution.
	\item[Authentication/Verification:] The service must provide a procedure to guarantee entity authentication, message content authentication and message origin authentication.
	\item[Key Distribution:] The service must provide a procedure to supply keys for parties legitimately asking for them.
\end{description}

Dias and Siriwardena~\cite{dias2020microservices} furthermore give insights to the key provisioning (distribution) process of netflix.
Netflix uses its own broker called Lemur for the key provisioning.
The key provisioning is performed in the following steps, which are visualized in figure~\ref{fig:key_provisioning_netflix}:
\begin{enumerate}
    \item During the continuous delivery process, each microservice gets a set of credentials that are good enough to access the Lemur APIs.
		This is done using an netflix internal tool called Metatron.
		The credentials from Metatron are long lived credentials, this means they can be used for longer period, so the following process can be repeated multiple times.
    \item The microservice talks to the Lemur API to obtain a signed certificate for its credentials.
		This can happen either, during the startup process of the microservice, or when the microservice is rotating its keys.
    \item Lemur creates a certificate signing request (CSR) addressed to the CA.
    \item The certificate is signed using the CA.
		Lemur is not a CA, but it knows how to integrate with a CA to generated signed certificates.
    \item Lemur returns the signed certificate to the microservice who can than use it to authenticate itself to other services.
\end{enumerate}
Therefore the developers do not have to worry about creating and signing certificates.
Instead, they have to implement the communication with the Lemur API.


\begin{figure}
	\centering
	\includegraphics{images/related-work/netflix-provisioning.pdf}
	\caption{Key provisioning of netflix using Lemur and Metatron~\cite{dias2020microservices}}
	\label{fig:key_provisioning_netflix}
\end{figure}

\section{Technologies}
\subsection{X509.Certificate}
X.509 certifcates binds the subject of a certificate to a public key.
They are used to assure the user of an certificate that the subject of the certificate owns the correspondig private key.
Certificate authorities sign certificates and each communication partner who trusts the CA trusts the certificates signed by it.
The most significant advantage of certificates is that they can be exchanged using untrusted communication channels because the signatures are not valid anymore when the contents of a certificate are changed.
Therefore manipulations can be detected, and manipulated certificates can be declined~\cite{x509rfc}.

\subsubsection{Trust Path}
When the client of a service wants to consume a service, which is hosted on a server, it has to obtain the server's certificate.
If the client does not know the public key of the CA who signed the server's certificate, he has to obtain it.
Obtaining the public key often results in chains because the client may have to work his way up until he reaches a CA he trusts.
Such chains are also called certification paths.
The way in which the clients can retrieve the CA certificates can be configured by the CA.

\subsubsection{Fields}
Depending on the version, a certificate can include more or less information.
The information is always stored inside the tbsCertificate, signatureAlgorithm, and signatureValue fields and can be expanded using extensions.

The \textbf{TBSCertificate} contains the data of the certificate, including the following information:
\begin{itemize}
    \item Subject of the certificate
    \item Issuer of the certificate
    \item public key of the subject
    \item Validity period
    \item Additional information
\end{itemize}

The \textbf{signatureAlogrithm} field stores the information, which cryptographic algorithm was used to sign the certificate.
Algorithms are declared by their identifier, the "OBJECT IDENTIFIER".
The most commonly used algorithms are the RSA\footnote{Rivest Shamir Adleman} algorithm and the Digital Signature Algorithm (DSA)~\cite{x509rfc}.

The \textbf{signatureValue} field contains the value of the digital signature.
It is obtained by signing the content of the tbsCertificate, using the algorithm specified in the signatureAlgorithm field.
The signature is used to verify the validity of the information embedded in the tbsCertificate field.

\subsubsection{Certificate Revocation}
A certificate can be revocated for the following reasons: 
\begin{itemize}
    \item Private key of the CA is compromised
    \item Private key of the microservice is compromised
    \item The holder of the certificate is no longer the identity, which requested the certificate 
    \item The CA finds out that the parameters provided in the CSR are invalid
\end{itemize}
The hardest part about the certificate revocation is to inform all participants about the certificates, which are revocated.
This is done using certificate revocation lists (CRL) or other revocation mechanics.
The big downside of CRLS is that the CA has to store a list of certificates, which are relocated, and the clients have to retrieve this list for every communication.
Caching can be used to reduce latencies.
Otherwise, it also reduces the security because a certificate can be revocated during the lifetime of the cache.
Especially a case in which the CA does not respond to the CRL query is tough to handle.
Therefore the certificate revocation is a significant downside of public-key based authentication, even if the Online Certificate Status Protocol (OSCP) tries to remedy the situation\cite{dias2020microservices}.

\subsection{JSON Web Token}
A JSON Web Token (JWT) is a container, which can carry authentication and authorization assertions and further information in a cryptographically safe manner.
An authentication assertion can be anything, which authenticates the user.
Usually, usernames or e-mail addresses are used to identify a user uniquely.
An authorization assertion can be any information about the access permissions of a user.
For example, a JWT can include the information, whether the user is an admin or an unprivileged user~\cite{dias2020microservices}. 

\subsubsection{Structure}
A JWT is decomposed into the header, the payload, and the signature.
The three parts are concatenated and separated by a dot~\cite{jwtdocauth0}.
A valid JWT could look like the JWT shown in figure~\ref{fig:myjwt}.
\begin{figure}
    \textcolor{red}{Header}.
	\textcolor{blue}{Payload}.
	\textcolor{darkgreen}{Signature} \\ \\
    \textcolor{red}{eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9}.
	\textcolor{blue}{eyJzdWIiOiIxMjM0NTY3ODkiLCJpYXQi\\OjE1MTYyMzkwMjIsInVzZXJuYW1lIjoiYmVuamFtaW4uZWxsbWVyIiwiZW1haWw\\iOiJiZW5qYW1pbi5lbGxtZXJAeWFob28uY29tIiwiYWRtaW4iOmZhbHNlfQ}.
	\textcolor{darkgreen}{0ksqN71oloNvq3IrY7w72uoTgPz9Gpn08p-KSbFulY0}
    \caption{Sample JSON Web Token}
    \label{fig:myjwt}
\end{figure}

The \textbf{header} contains the metadata related to the JWT, which is usually the type of the token and the signature algorithm.
The specification defines that only HS256\footnote{HMAC SHA-256} and none algorithm must be implemented  by conforming JWT implementation.
It is recommended to additionally implement the algorithms RS256 and ES256\footnote{Elliptic Curve Digital Signature Algorithm (ECDSA) with 256-bit key}~\cite{jwtdocauth0, jwtrfc}.
The base64 encoded header is the first part of the JWT.

The \textbf{payload} is a set of registered and custom claims.
A claim is a piece of information about an entity.
The JWT specification defines registered claims, which are not mandatory for all cases but should provide a good starting point for a set of useful claims to ensure interoperability.
Custom claims can be defined by the software architects, on their own, depending on their needs.
The custom claims registered in the IANA registry are called public claims, and those not registered in the IANA registry are called private claims~\cite{jwtdocauth0, jwtrfc}.
The base64 encoded payload is the second part of the JWT.

The chosen signature algorithm signs the base64 encoded header, the base64 encoded payload, and a secret.
The \textbf{signature} provides integrity for the message, and if it was signed with a private key, it additionally provides authentication~\cite{jwtdocauth0}.
The base64 encoded signature is the third part of the JWT.

\subsection{Transport Layer Security}
The Transport Layer Security (TLS) Protocol provides authentication, integrity, and confidentiality for the communication between two parties.
It consists of two layers, the handshake protocol, and the record protocol~\cite{turnertls}.

\subsubsection{mTLS} \label{sec:mtls}
TLS itself is also called one-way TLS because it helps the client to identify the server, but not the server to identify the client.
Therefore mutual TLS (mTLS) was introduced to provide authentication in both directions.
The client and the server must own a private/public key pair, so it is more suited for the communication between two systems and not between users and servers~\cite{dias2020microservices}. 

\subsubsection{Handshake Protocol}
The handshake protocol is responsible for negotiating a cipher suite and for the authentication using X.509 certificates.
The cipher suite declares the key exchange algorithm, the signature algorithm, the symmetric encryption algorithm, including the mode of the encryption algorithm and the hashing algorithm~\cite{turnertls, kurbatov2021design}.
The handshake varies on the key exchange method, but it can be separated into the following steps~\cite{krawczyk2013security}:
\begin{enumerate}
    \item The server and the client exchange Hello messages
    \item The server sends its certificate to the client
    \item The client sends a pre-master secret to the server and if mTLS is used, the client sends his certificate to the server
    \item The client and the server finish the handshake, using the independently computed master secret
\end{enumerate}
The steps of the handshake will be explained in more detail in chapter~\ref{sec:tlshandshake_details}.

\subsubsection{Record Protocol}
The record protocol provides a secure channel for the communication between the parties.
This is done by using the algorithms declared in the cipher suite.
Confidentiality is assured, using symmetric encryption, and integrity is provided by Message Authentication Codes (MAC)~\cite{kurbatov2021design, krawczyk2013security}.

